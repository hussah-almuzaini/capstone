<!-- <!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>ูุณุงุนุฏ ุงูููููููู</title>
  <link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/static/style.css" />
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon">
</head>
<body>
  <img id="logo" src="/static/logo.png" alt="ุดุนุงุฑ ุจุตูุฑ">
  <h1>๐ ูุณุงุนุฏ ุงูููููููู - ุงูุจุญุซ ุงูุตูุชู</h1>
  <p id="heardText">๐ง ูู ุงูุชุธุงุฑ ุงูุฃูุฑ ุงูุตูุชู...</p>
  <pre id="result"></pre>
  <audio id="audio" controls style="display:none"></audio>
  <video id="video" width="320" height="240" autoplay muted></video>

  <script>
    let ws;
    let detectionTarget = "person";
    function playAudioBlob(blob, callback = null) {
      const audio = document.getElementById("audio");
      const url = URL.createObjectURL(blob);

      // Stop current playback
      audio.pause();
      audio.currentTime = 0;

      // Replace source and play
      audio.src = url;
      audio.style.display = 'block';

      // Play and wait until it ends before allowing next
      audio.play().then(() => {
        audio.onended = () => {
          if (callback) callback();
        };
      }).catch(e => {
        console.warn("Audio error:", e.message);
        if (callback) callback();  // Fallback even on error
      });
    }
    function speak(text, callback = null) {
      const formData = new FormData();
      formData.append("text", text);
      fetch("/speak", { method: "POST", body: formData })
        .then(response => response.blob())
        .then(blob => {
          playAudioBlob(blob, callback);
        });
    }

    function listenForCommandOrTarget(callback) {
      const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      r.lang = 'ar-SA';
      r.onresult = e => {
        const t = e.results[0][0].transcript.trim().toLowerCase();
        document.getElementById("heardText").innerText = `๐ฌ ุณูุน: ${t}`;

        if (t.includes("ุงูุฑุฆูุณูุฉ") || t.includes("ุฑุฌูุน") || t.includes("ููู")|| t.includes("ุงุฑุฌุน")|| t.includes("ุงุฎุฑุฌ")) {
          detectionTarget = "back";
          speak("ุฌุงุฑู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ");
          window.location.href = "/";
          return;
        }

        if (t.includes("ุดุฎุต") || t.includes("1")) {
          detectionTarget = "person";
        } else if (t.includes("ูุฑุณู") || t.includes("2")) {
          detectionTarget = "chair";
        } else if (t.includes("ูุงุชู") || t.includes("3")) {
          detectionTarget = "cell phone";
        } else if (t.includes("ุญููุจุฉ") || t.includes("4")) {
          detectionTarget = "handbag";
        } else if (t.includes("ุทุงููุฉ") || t.includes("5")) {
          detectionTarget = "dining table";
        } else if (t.includes("ุชููุงุฒ") || t.includes("6")) {
          detectionTarget = "tv";
        }
          else {
          speak("ูู ุฃููู ุงูุฃูุฑ. ุญุงูู ูุฑุฉ ุฃุฎุฑู.");
          return;
        }

        if (callback) callback();
      };
      r.start();
    }

    async function startDetection() {
      ws = new WebSocket(`ws://${location.host}/ws/depth-live`);
      ws.onopen = () => {
        ws.send(JSON.stringify({ target: detectionTarget }));
      };
      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        document.getElementById('result').textContent = data.description || data.error || '';
        if (data.audio_url) {
          const audio = document.getElementById('audio');
          fetch(data.audio_url)
            .then(response => response.blob())
            .then(blob => {
              playAudioBlob(blob, () => {
                speak("ูู ุชุฑูุฏ ุงููุดู ุนู ูุฏู ุขุฎุฑ ุฃู ุงูุฑุฌูุนุ", () => {
                  listenForCommandOrTarget(() => {
                    if (detectionTarget === "back") {
                      speak("ุฌุงุฑู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ");
                      window.location.href = "/";
                    } else {
                      ws.send(JSON.stringify({ target: detectionTarget }));
                    }
                  });
                });
              });
            });
          // audio.onended = () => {
          //   speak("ูู ุชุฑูุฏ ุงููุดู ุนู ูุฏู ุขุฎุฑ ุฃู ุงูุฑุฌูุนุ", () => {
          //     listenForCommandOrTarget(() => {
          //       ws.send(JSON.stringify({ target: detectionTarget }));
          //     });
          //   });
          // };
        }
      };

      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      setInterval(() => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
        canvas.toBlob(blob => {
          if (ws.readyState === 1) {
            const reader = new FileReader();
            reader.onload = () => {
              ws.send(reader.result);
            };
            reader.readAsDataURL(blob);
          }
        }, 'image/jpeg', 0.7);
      }, 300);
    }

    window.onload = () => {
      speak("ุงุฎุชุฑ ุงููุฏู: 1 ุดุฎุตุ 2 ูุฑุณูุ 3 ูุงุชูุ 4 ุญููุจุฉุ 5 ุทุงููุฉุ 6 ุชููุงุฒ", () => {
        listenForCommandOrTarget(() => {
          startDetection();
        });
      });
    };
  </script>
</body>
</html> -->
<!-- old version works like a charm -->



<!-- new version should be better -->
<!-- 
<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>ูุณุงุนุฏ ุงูููููููู</title>
  <link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/static/style.css" />
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon">
</head>
<body>
  <img id="logo" src="/static/logo.png" alt="ุดุนุงุฑ ุจุตูุฑ">
  <h1>๐ ูุณุงุนุฏ ุงูููููููู - ุงูุจุญุซ ุงูุตูุชู</h1>
  <p id="heardText">๐ง ูู ุงูุชุธุงุฑ ุงูุฃูุฑ ุงูุตูุชู...</p>
  <pre id="result"></pre>
  <audio id="audio" controls style="display:none"></audio>
  <video id="video" width="320" height="240" autoplay muted></video>

  <script>
    let ws;
    let detectionTarget = "person";
    let detectionCooldown = {};
    let lastPromptTime = 0;
    const audio = document.getElementById("audio");

    function speak(text, callback = null) {
      const formData = new FormData();
      formData.append("text", text);
      fetch("/speak", { method: "POST", body: formData })
        .then(response => response.blob())
        .then(blob => {
          const url = URL.createObjectURL(blob);
          audio.pause();
          audio.currentTime = 0;
          audio.src = url;
          audio.style.display = 'block';
          audio.play();
          if (callback) audio.onended = callback;
        });
    }

    function listenForExitCommand() {
      const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      r.lang = 'ar-SA';
      r.onresult = e => {
        const t = e.results[0][0].transcript.trim().toLowerCase();
        if (t.includes("ุงูุฑุฆูุณูุฉ") || t.includes("ุฑุฌูุน") || t.includes("ุชููู")) {
          speak("ุฌุงุฑู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ", () => {
            window.location.href = "/";
          });
        }
      };
      r.start();
    }

    async function startDetection() {
      ws = new WebSocket(`ws://${location.host}/ws/depth-live`);
      ws.onopen = () => {
        ws.send(JSON.stringify({ target: detectionTarget }));
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data.description) {
          const now = Date.now();
          // if (!detectionCooldown[data.description] || (now - detectionCooldown[data.description] > 7000)) {
          //   detectionCooldown[data.description] = now;
          document.getElementById('result').textContent = data.description;

          if (data.audio_url) {
            fetch(data.audio_url)
              .then(response => response.blob())
              .then(blob => {
                const url = URL.createObjectURL(blob);
                audio.pause();
                audio.currentTime = 0;
                audio.src = url;
                audio.style.display = 'block';
                audio.play();
              });
          }
          // }
        }
      };

      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      setInterval(() => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
        canvas.toBlob(blob => {
          if (ws.readyState === 1) {
            const reader = new FileReader();
            reader.onload = () => {
              ws.send(reader.result);
            };
            reader.readAsDataURL(blob);
          }
        }, 'image/jpeg', 0.7);
      }, 500);
    }

    window.onload = () => {
      speak("ูุฑุญุจูุงุ ุงุฎุชุฑ ุงููุฏู ุงููุทููุจ: 1 ุดุฎุตุ 2 ูุฑุณูุ 3 ููุจููุชุฑุ 4 ุญููุจุฉุ 5 ุทุงููุฉุ 6 ุชููุงุฒ. ุฃู ูู ุฑุฌูุน ููุนูุฏุฉ ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ.", () => {
        const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        r.lang = 'ar-SA';
        r.onresult = e => {
          const t = e.results[0][0].transcript.trim().toLowerCase();
          if (t.includes("ุดุฎุต") || t.includes("1")) detectionTarget = "person";
          else if (t.includes("ูุฑุณู") || t.includes("2")) detectionTarget = "chair";
          else if (t.includes("ููุจููุชุฑ") || t.includes("3")) detectionTarget = "laptop";
          else if (t.includes("ุญููุจุฉ") || t.includes("4")) detectionTarget = "backpack";
          else if (t.includes("ุทุงููุฉ") || t.includes("5")) detectionTarget = "dining table";
          else if (t.includes("ุชููุงุฒ") || t.includes("6")) detectionTarget = "tv";
          else if (t.includes("ุฑุฌูุน") || t.includes("ุงูุฑุฆูุณูุฉ")) {
            window.location.href = "/";
            return;
          }
          startDetection();
          // Start passive exit listening every 15 seconds
          setInterval(listenForExitCommand, 15000);
        };
        r.start();
      });
    };
  </script>
</body>
</html> -->



<!-- extra version -->

<!-- <!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>ูุณุงุนุฏ ุงูููููููู</title>
  <link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/static/style.css" />
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon">
</head>
<body>
  <img id="logo" src="/static/logo.png" alt="ุดุนุงุฑ ุจุตูุฑ">
  <h1>๐ ูุณุงุนุฏ ุงูููููููู - ุงูุจุญุซ ุงูุตูุชู</h1>
  <p id="heardText">๐ง ูู ุงูุชุธุงุฑ ุงูุฃูุฑ ุงูุตูุชู...</p>
  <pre id="result"></pre>
  <audio id="audio" controls style="display:none"></audio>
  <video id="video" width="640" height="440" autoplay muted></video>

  <script>
    let ws;
    let detectionTarget = "person";
    const audio = document.getElementById("audio");
    let isListening = false;
    let lastDescription = "";

    function speak(text, callback = null) {
      const formData = new FormData();
      formData.append("text", text);
      fetch("/speak", { method: "POST", body: formData })
        .then(response => response.blob())
        .then(blob => {
          const url = URL.createObjectURL(blob);
          audio.pause();
          audio.currentTime = 0;
          audio.src = url;
          audio.style.display = 'block';

          audio.play().then(() => {
            console.log("๐ Audio playing...");
          }).catch(err => {
            console.warn("โ Audio play failed:", err.message);
          });

          audio.onended = () => {
            console.log("โ Audio ended");
            isListening = false;
            if (callback) callback();
          };

          audio.onerror = () => {
            console.warn("โ Audio playback error");
            isListening = false;
            if (callback) callback();
          };
        });
    }

    function continuousExitListener() {
      if (isListening || !audio.paused || userCommandInProgress) return;

      isListening = false;
      userCommandInProgress = false;

      speak("ุฃูุง ุฃุณุชูุน ุงูุขู. ูู ุฑุฌูุน ููุนูุฏุฉ ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ.", () => {
        try {
          const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
          r.lang = 'ar-SA';

          r.onresult = e => {
            const t = e.results[0][0].transcript.trim().toLowerCase();
            if (t.includes("ุฑุฌูุน") || t.includes("ุงูุฑุฆูุณูุฉ") || t.includes("ุชููู")) {
              speak("ุฌุงุฑู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ", () => {
                window.location.href = "/";
              });
            } else {
              userCommandInProgress = false;
            }
          };

          r.onend = () => {
            isListening = false;
            userCommandInProgress = false;
          };
          r.onerror = () => {
            isListening = false;
            userCommandInProgress = false;
          };

          r.start();
        } catch (err) {
          console.error("SpeechRecognition error:", err);
          isListening = false;
          userCommandInProgress = false;
        }
      });
    }


    async function startDetection() {
      ws = new WebSocket(`ws://${location.host}/ws/depth-live`);

      ws.onopen = () => {
        ws.send(JSON.stringify({ target: detectionTarget }));
        console.log("โ WebSocket opened");
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        console.log("๐ฆ WS Message Received:", JSON.stringify(data));

        if (!data.description) return;
        if (data.description === lastDescription) return;  // skip duplicates
        lastDescription = data.description;

        document.getElementById('result').textContent = data.description;

        if (data.audio_url) {
          fetch(data.audio_url)
            .then(response => response.blob())
            .then(blob => {
              const url = URL.createObjectURL(blob);
              if (audio.src !== url) {
                audio.pause();
                audio.currentTime = 0;
                audio.src = url;
              }
              audio.style.display = 'block';
              audio.play().then(() => {
                console.log("๐ Audio playing...");
              }).catch(err => {
                console.warn("โ Audio play failed:", err.message);
              });
            });
        }
      };

      ws.onclose = () => {
        console.warn("โ WebSocket closed");
        speak("ุชู ููุฏ ุงูุงุชุตุงู ุจุงูุฎุงุฏู. ูุฑุฌู ุฅุนุงุฏุฉ ุชุญููู ุงูุตูุญุฉ.");
      };

      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      setInterval(() => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
        canvas.toBlob(blob => {
          if (ws.readyState === 1) {
            const reader = new FileReader();
            reader.onload = () => {
              ws.send(reader.result);
            };
            reader.readAsDataURL(blob);
          }
        }, 'image/jpeg', 0.7);
      }, 500);
    }

    window.onload = () => {
      speak("ูุฑุญุจูุงุ ุงุฎุชุฑ ุงููุฏู ุงููุทููุจ: 1 ุดุฎุตุ 2 ูุฑุณูุ 3 ููุจููุชุฑุ 4 ุญููุจุฉุ 5 ุทุงููุฉุ 6 ุชููุงุฒุ 7 ูุงุชู. ุฃู ูู ุฑุฌูุน ููุนูุฏุฉ ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ.", () => {
        const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        r.lang = 'ar-SA';

        r.onresult = e => {
          const t = e.results[0][0].transcript.trim().toLowerCase();
          if (t.includes("ุดุฎุต") || t.includes("1")) detectionTarget = "person";
          else if (t.includes("ูุฑุณู") || t.includes("2")) detectionTarget = "chair";
          else if (t.includes("ููุจููุชุฑ") || t.includes("3")) detectionTarget = "laptop";
          else if (t.includes("ุญููุจุฉ") || t.includes("4")) detectionTarget = "backpack";
          else if (t.includes("ุทุงููุฉ") || t.includes("5")) detectionTarget = "dining table";
          else if (t.includes("ุชููุงุฒ") || t.includes("6")) detectionTarget = "tv";
          else if (t.includes("ูุงุชู") || t.includes("7")) detectionTarget = "cell phone";
          else if (t.includes("ุฑุฌูุน") || t.includes("ุงูุฑุฆูุณูุฉ")) {
            window.location.href = "/";
            return;
          }

          startDetection();
          setInterval(continuousExitListener, 30000);
        };

        r.onerror = () => console.warn("๐๏ธ Initial SpeechRecognition error");
        r.start();
      });
    };
  </script>
</body>
</html> -->


<!-- final version -->
<!DOCTYPE html>
<html lang="ar">
<head>
  <meta charset="UTF-8" />
  <title>ูุณุงุนุฏ ุงูููููููู</title>
  <link href="https://fonts.googleapis.com/css2?family=Tajawal:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/static/style.css" />
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon">
</head>
<div class="corner-button" id="corner-top-left" onclick="window.location.href='/'"></div>
<style>
  .corner-button {
    position: fixed;
    width: 20vw;
    height: 20vh;
    z-index: 999;
    background: transparent;
  }
  #corner-top-left {
    top: 0;
    left: 0;
  }
</style>
<body>
  <img id="logo" src="/static/logo.png" alt="ุดุนุงุฑ ุจุตูุฑ">
  <h1>๐ ูุณุงุนุฏ ุงูููููููู - ุงูุจุญุซ ุงูุตูุชู</h1>
  <p id="heardText">๐ง ูู ุงูุชุธุงุฑ ุงูุฃูุฑ ุงูุตูุชู...</p>
  <pre id="result"></pre>
  <audio id="audio" controls style="display:none"></audio>
  <audio id="beep" src="/static/beep.wav" preload="auto"></audio>
  <video
    id="video"
    width="640"
    height="480"
    autoplay
    muted
    style="display: block; margin: 0 auto; background-color: #000; border: 2px solid #ccc;"
  ></video>

  <script>
    let ws;
    let detectionTarget = "person";
    const audio = document.getElementById("audio");
    const beep = document.getElementById("beep");
    let isListening = false;
    let userCommandInProgress = false;
    let lastDescription = "";
    let detectionCount = 0;
    let detectionLocked = false;
    let timeoutHandle = null;

    function speak(text, callback = null) {
      const formData = new FormData();
      formData.append("text", text);
      fetch("/speak", { method: "POST", body: formData })
        .then(response => response.blob())
        .then(blob => {
          const url = URL.createObjectURL(blob);
          audio.pause();
          audio.currentTime = 0;
          audio.src = url;
          audio.style.display = 'block';

          audio.play().then(() => {
            console.log("๐ Audio playing...");
          }).catch(err => {
            console.warn("โ Audio play failed:", err.message);
          });

          audio.onended = () => {
            console.log("โ Audio ended");
            isListening = false;
            if (callback) callback();
          };

          audio.onerror = () => {
            console.warn("โ Audio playback error");
            isListening = false;
            if (callback) callback();
          };
        });
    }

    function stopDetectionStream() {
      if (ws && ws.readyState === 1) {
        ws.close();
        console.log("๐ Detection stream stopped.");
      }
    }

    function askAfterDetections() {
      detectionLocked = true;
      stopDetectionStream();

      speak("ูู ุชุฑูุฏ ุงูุงุณุชูุฑุงุฑ ูู ุงูุจุญุซ ุนู ููุณ ุงููุฏูุ ุฃู ุงุฎุชูุงุฑ ูุฏู ุขุฎุฑุ ุฃู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉุ", () => {
        const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        r.lang = 'ar-SA';

        const cleanup = () => {
          clearTimeout(timeoutHandle);
          isListening = false;
          userCommandInProgress = false;
          detectionLocked = false;
        };

        r.onresult = e => {
          const t = e.results[0][0].transcript.trim().toLowerCase();
          if (t.includes("ุฑุฌูุน") || t.includes("ุงูุฑุฆูุณูุฉ")) {
            speak("ุฌุงุฑู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ", () => {
              window.location.href = "/";
            });
          } else if (t.includes("ูุฏู") || t.includes("ุจุญุซ")) {
            window.location.reload();
          } else if (t.includes("ุงุณุชูุฑุงุฑ") || t.includes("ุชุงุจุน")) {
            detectionCount = 0;
            cleanup();
            startDetection();
          } else {
            cleanup();
            startDetection();
          }
        };

        r.onerror = r.onend = () => {
          cleanup();
        };

        timeoutHandle = setTimeout(() => {
          console.warn("โ Timeout: no response. Going back to homepage.");
          speak("ูู ูุชู ุงูุงุณุชุฌุงุจุฉุ ุณูุชู ุงูุฑุฌูุน ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ", () => {
            window.location.href = "/";
          });
        }, 15000); // 15 sec timeout

        beep.play();
        r.start();
        document.getElementById("heardText").innerText = "๐ค ุงููููุฑูููู ูุนูู: ุงุฎุชุฑ ุงูุงุณุชูุฑุงุฑ ุฃู ูุฏู ุขุฎุฑ ุฃู ุงูุฑุฌูุน.";
      });
    }

    async function startDetection() {
      ws = new WebSocket(`ws://${location.host}/ws/depth-live`);

      ws.onopen = () => {
        ws.send(JSON.stringify({ target: detectionTarget }));
        console.log("โ WebSocket opened");
      };

      ws.onmessage = (event) => {
        if (detectionLocked) return;

        const data = JSON.parse(event.data);
        console.log("๐ฆ WS Message Received:", JSON.stringify(data));

        if (!data || typeof data !== 'object' || !data.description) return;
        if (data.description === lastDescription) return;
        if (userCommandInProgress) return;

        lastDescription = data.description;
        document.getElementById('result').textContent = data.description;
        detectionCount++;

        const playAndCheck = () => {
          if (detectionCount >= 3) {
            askAfterDetections();
          }
        };

        if (data.audio_url) {
          fetch(data.audio_url)
            .then(response => response.blob())
            .then(blob => {
              const url = URL.createObjectURL(blob);
              if (audio.src !== url) {
                audio.pause();
                audio.currentTime = 0;
                audio.src = url;
              }
              audio.style.display = 'block';
              audio.play().then(() => {
                console.log("๐ Audio playing...");
              }).catch(err => {
                console.warn("โ Audio play failed:", err.message);
              });
              audio.onended = playAndCheck;
            });
        }
      };

      ws.onclose = () => {
        console.warn("โ WebSocket closed");
      };

      const video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      setInterval(() => {
        if (!detectionLocked && ws.readyState === 1) {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          ctx.drawImage(video, 0, 0);
          canvas.toBlob(blob => {
            const reader = new FileReader();
            reader.onload = () => {
              ws.send(reader.result);
            };
            reader.readAsDataURL(blob);
          }, 'image/jpeg', 0.7);
        }
      }, 500);
    }

    window.onload = () => {
      speak("ูุฑุญุจูุงุ ุงุฎุชุฑ ุงููุฏู ุงููุทููุจ: 1 ุดุฎุตุ 2 ูุฑุณูุ 3 ููุจููุชุฑุ 4 ุญููุจุฉุ 5 ุทุงููุฉุ 6 ุชููุงุฒ. ุฃู ูู ุฑุฌูุน ููุนูุฏุฉ ุฅูู ุงูุตูุญุฉ ุงูุฑุฆูุณูุฉ.", () => {
        const r = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        r.lang = 'ar-SA';

        r.onresult = e => {
          const t = e.results[0][0].transcript.trim().toLowerCase();
          if (t.includes("ุดุฎุต") || t.includes("1")) detectionTarget = "person";
          else if (t.includes("ูุฑุณู") || t.includes("2")) detectionTarget = "chair";
          else if (t.includes("ููุจููุชุฑ") || t.includes("3")) detectionTarget = "laptop";
          else if (t.includes("ุญููุจุฉ") || t.includes("4")) detectionTarget = "backpack";
          else if (t.includes("ุทุงููุฉ") || t.includes("5")) detectionTarget = "dining table";
          else if (t.includes("ุชููุงุฒ") || t.includes("6")) detectionTarget = "tv";
          else if (t.includes("ุฑุฌูุน") || t.includes("ุงูุฑุฆูุณูุฉ")) {
            window.location.href = "/";
            return;
          }

          startDetection();
        };

        r.onerror = () => console.warn("๐๏ธ Initial SpeechRecognition error");
        r.start();
      });
    };
  </script>
<div class="bg"></div>
<div class="bg bg2"></div>
<div class="bg bg3"></div>
<div class="bg bg4"></div>

</body>
</html>
